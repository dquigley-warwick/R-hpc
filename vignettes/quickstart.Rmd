---
title: "Quick Start"
output:
  rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Quick Start}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{css echo=FALSE}
img {
    border: 0px !important;
    margin: 2em 2em 2em 2em !important;
}
code {
    border: 0px !important;
}
kbd {
    background-color: #eee;
    border-radius: 3px;
    border: 1px solid #b4b4b4;
    box-shadow: 0 1px 1px rgba(0, 0, 0, .2), 0 2px 0 0 rgba(255, 255, 255, .7) inset;
    color: #333;
    display: inline-block;
    font-size: .85em;
    font-weight: 700;
    line-height: 1;
    padding: 2px 4px;
    white-space: nowrap;
}
```

```{r echo=FALSE, results="hide"}
knitr::opts_chunk$set(
    cache = FALSE,
    echo = TRUE,
    collapse = TRUE,
    comment = "#>"
)
```

## Prerequesites

Working on High-Performance Computing (HPC) facilities, we primarily interface
with the systems via a command-line shell. We expect the people in this course
to have a wide range of expertise and different starting points concerning the
use of the command-line, which will make it easier or more challenging for
participants, depending on where they are coming from.

Similarly, we expect participants to start with different operating systems,
e.g. not only Windows but also macOS and different Linux flavors. In order to
keep the course consistent we recommend Windows users to work through the
materials using the Windows Subsystem for Linux (WSL 2.0). This should be
available for any up-to-date Windows 10 or later. We expect that macOS and Linux
users are already familiar with their terminal.

## Connecting to the computing cluster

Command-line connections to the HPC are established using the Secure Shell tool
(SSH). From a terminal, you can connect to Sulis using the following line:

```{sh eval=FALSE}
ssh -i <your keyfile> <user>@login.sulis.ac.uk
```

Since this is a bit tedious, we can outsource most of the information to a
`~/.ssh/config` file with the following contents:

```{sh eval=FALSE}
Host sulis
    Hostname login.sulis.ac.uk
    User <username>
#    ProxyCommand ssh <proxy> -W %h:%p   # when connecting via an SSH proxy
    IdentityFile ~/.ssh/<sulis_rsa>
```

Having it set up like this, establishing the connection is as simple as typing:

```{sh eval=FALSE}
ssh sulis
```

This will come in handy when not only connecting to the HPC once, but also
copying files between your local machine and the HPC.

Note, however, that in both cases you will still need to decrypt your private
key file with your passphrase (which, at least on macOS and Linux can be
automated using your OS keychain) and the 2FA token once a day.

## Setting up R

```{sh eval=FALSE}
which R
# /usr/bin/which: no R in [...]
```

```{sh eval=FALSE}
module load GCC/11.2.0 OpenMPI/4.1.1 R/4.1.2
which R
# /sulis/easybuild/software/R/4.1.2-foss-2021b/bin/R
```

## Running an interactive job

The simplest way to request an interactive job is to use Slurm's `srun` command
where we specify that we want to run a shell (specified by the `$SHELL`
environment variable) that is connected to our terminal input and output
(`--pty`). In addition, we need to specify the account our requested resources
will be budgeted to (`--account`) We can do that by running:

```{sh eval=FALSE}
srun --account su105 --pty $SHELL
```

You will see that your command prompt changes from `user@login` to
`user$nodeXX`, which means that we are now connected to a compute node instead
of the login node. Here, we are allowed to run heavy computations within the
resource constraints that we specified.

First, let's get an overview of which processes are already running on this
node. This we can do by running the resource monitor `htop`:

```{sh eval=FALSE}
htop
```

In this overview, we can see how many cores the compute node has, how many
processes are running, and how much memory is used. Depending on how much of
those resources we requested (and the overall load), we will see that at least
our resource allocation is still free. We do, however, need to stay within our
allocation (and not the overall amount of available resources), because
otherwise our processes will be terminated automatically.

If we have loaded the R module beforehand, we'll see that the `$PATH` (the
environment variable where our shell looks for executables) is still set up to
include R. We can check this by asking for the R path:

```{sh eval=FALSE}
which R
```

We can then run or via the command-line, as we can on our local machines as
well. Running `R` will give us an R command prompt:

```{sh echo=FALSE}
R --no-save --no-restore -e "quit()"
```

We can use `R` as we could use the R shell in e.g. RStudio as well:

```{r}
x = 5
y = 3
x * y
```

## Copying files

There are different options for getting your files to the compute cluster. One
option is to edit all files locally, and then copy them over SSH. So, for
instance, one could have a local file `text.txt` and copy it over:

```{sh eval=FALSE}
scp text.txt host:
```

where you specified `host` in your `~/.ssh/config` before, or otherwise you may
need to specify the user name, key file, and host manually (this will look
differently if you are using a graphical SSH client). The `:` is used for the
`scp` command to know which one is the remote end, i.e. you could use the
following to copy the same file from the remote to your local end:

```{sh eval=FALSE}
scp host:test.txt .
```

Here, the `scp` command looks for `test.sh` in your home directory (`~`; this is
the default if no directory is specified) and will copy it to your current
directory (`.`).

If you want to copy directories you need to use recursive copying, i.e. `scp
-r`.

Another, and maybe better alternative is the `rsync` command. This will keep
timestamps intact, and can be used to copy only files that have updated
timestamps (`-u`) compared to the local files (`-v` will print the files while
copying):

```{sh eval=FALSE}
rsync -uvr host:test.txt .
```

## Editing files

For either making small changes or iterative work, it is often more convenient
to edit files directly on the computing cluster instead of editing them locally
and then copy them.

There are multiple text-based editors that work in a terminal, such as `nano`,
`emacs` and `vim`. `nano` is a minimalist editor without any special features,
and is often recommended to users new to the terminal. The problem with that is
that we get very quickly stuck at a local optimum, where we can make simple
changes to a file, but will never get features such as syntax highlighting. The
other two editors on the other hand either have or can be extended to have
any/every feature imaginable.

This is why for this course, we will show some basic features of `nvim`
(`neovim`, a modern implementation of `vim`) instead. If you are already a user
of `emacs`, please feel free to use this editor instead.

To edit a simple text file, we can run:

```{sh eval=FALSE}
nvim myfile.txt
```

You will see that the console gets cleared, and we are shown the contents of an
empty file instead. Try typing a couple of <kbd>a</kbd> in the file:

```{sh eval=FALSE}
aaaa
```

You will see the characters show up, as you would from another text editor as
well. Notice, however, that the first <kbd>a</kbd> you typed did not show up,
only all subsequent <kbd>a</kbd>s. This is because this editor has a "normal"
and an "edit" mode. By typing the first <kbd>a</kbd>, we switched from the first
to the latter.

We can now use <kbd>Esc</kbd> to switch back from the edit to the normal mode.
In normal mode, we can type `:w` <kbd>Enter</kbd> to write the file, or `:wq` to
write the file and quit the editor. `:q!` will exit without saving any changes.

This is all you need to know to make `vim` as useful as `nano`. However, if we
now for instance edit an `.r` file we also get syntax highlighting. This feature
alone makes it worth to use `nvim` instead of `nano`.

You can explore more features by running `vimtutor` from the command-line, which
is an interactive tool to familiarize yourself with how to use it effectively.

## Compute resources

For now, we have submitted our job while specifying only the minimum required
parameters and relying on the defaults for others. For instance, we have not
specific a `partition`, which is one of several job queues that we can submit
our jobs to. To get an overview of which are available, we can use the `sinfo`
command:

```{sh eval=FALSE}
sinfo
```

Here, we see the different partitions listed and a number of nodes associated
with each of them, including the walltime (maximum amount of time that a job can
request) for each queue. You will see that one queue is marked with a `*`. This
denotes the default queue, which we have been using by not specifying any
particular queue via the `--partition` parameter.

One argument that we did specify but not explain in more detail is the
`account`. This specifies the connection between your user name and a collection
of resources available that you can use, which are then subtracted from this
budget. You can check which accounts your user has access to by typing:

```{sh eval=FALSE}
sacctmgr show associations where user=<your user name>
```

You will likely only belong to one account, or project, at this time (which was
the one created for this course).

## Job submission scripts

Usually, you will want to run more complex computations than can be specified
with a single `srun`. For running multiple commands on multiple hosts, it is
often better to specify the resource requirements and exact commands using a job
submission script. This may look like the following:

```{sh eval=FALSE}
#!/bin/sh
#SBATCH --account su105
#SBATCH --partition compute
#SBATCH --ntasks 1
#SBATCH --cpus-per-task 1
#SBATCH --mem 1024M
#SBATCH --time 8:00:00

srun uname -n
```

We can submit this script by saving it to a script file and then running `sbatch
<script>`. It should tell us something like:

> Submitted batch job 1290046

where the number is the identifier of the job (and will be different with
multiple runs).

After we started it, we can check all jobs that our user is running by typing:

```{sh eval=FALSE}
squeue -u <username>
```

This should list a job with the above ID, show that it is currently running, and
the node the job is running on. We can also get detailed information about the
job using `scontrol`:

```{sh eval=FALSE}
scontrol show jobid <jobid>
```

This information will be available while the job is running and some (short)
time after it is finished. We can now also see resources that we did not
explicitly request, e.g. that the time limit was 1 hour, that we used the
`compute` partition, and were able to use up to 2 Gb of memory.

After the job started, it will create an output file called `slurm-xxxxxx.out`
(where `xxxxxx` is the job id) with the standard output of the command (the
standard output is what would have otherwise been printed to the console). After
it is finished, it will contain the output of `uname -n`, which is the name of
the node the command was run on. If all went well, it should contain `nodeXX`
and not `login`, which means that it was run on one of the compute nodes.

There's quite a few lines in there, so let's break this down:

* `#!/bin/sh` is called a shebang and specifies which application should be used
  to run the script, which is required by `sbatch` (otherwise it will refuse to
  submit the job)
* `#SBATCH --account` is needed again to budget the resources correctly
* `#SBATCH --parititon` this time we specific the `compute` partition explicitly
* `#SBATCH --ntasks` lists the tasks (computations) this job contains
* `#SBATCH --cpus-per-task` specifies the numbers of CPUs per task
* `#SBATCH --mem` specifies the amount of memory requested; this is in total,
  other options include `--mem-per-task`, `--mem-per-cpu`, or `--mem-per-gpu`.
  Memory multipliers such as `K`, `M` and `G` are supported (kilobytes,
  megabytes and gigabytes, respectively).
* `#SBATCH --time` is the maximum amount of time after which the job will be
  terminated (`dd-hh:mm:ss`)
* `#SBATCH` commands need to be directly following the shebang, otherwise they
  will be ignored
* `srun` specifies the command to be run; it is not required for running
  individual computations, but helps set up parallel helpers, such as running
  the call once per task, or e.g. setting up MPI if this is used

### Exercise

* Create a batch submission script like the one above using the command-line
  editor on the cluster
* Submit it using `sbatch <script>`, both with and without the `srun`. What
  changes?
* What happens with we change the `ntasks` parameter to `2`, both with and
  without the `srun` command?

## R on HPC

R's best developed parallel capabilities is running computations on multiple
cores. Here, we will briefly outline which approaches are commonly used. For
simplicity, let's consider a simple R function that sleeps for a couple of
seconds:

```{r}
fsleep = function(i) {
    print("starting ", i)
    Sys.sleep(1)
    print("done!")
}

fsleep(1)
```

If we need to call this function 10 times, we could use something like `lapply`:

```{r}
system.time({ lapply(1:10, fsleep) })
```

This will, unsurprisingly, take 10 times as long as an individual call to
`fsleep()`. For many use cases, it makese sense to run computations (done in
reality instead of just sleeping) in parallel. The probably most integrated
solution is the `parallel` package, which is one of the core packages
distributed with a standard R installation by default.

```{r}
system.time({ parallel::mclapply(1:10, fsleep) })
```

However, there are also other possibilities, e.g. the
[`foreach`](https://cran.r-project.org/package=foreach) package that enables
parallel processing using the `%dopar%` command, or the
[`future`](https://cran.r-project.org/package=future) package by using
`plan(multisession)`.

#### Exercise

* Create a "sleep script" on the computing cluster and a submission script that
  will request 1 task with 5 cores. Submit this script as a job. How long does
  it take? Does the runtime make sense?
* Submit the same script using a parallel `foreach` loop and a `PSOCK` cluster.
  Does it run? Do the results make sense?
* A newer approach that aims at providing a common interface to many parallel
  backends is the `future` package. Can you run the above example using
  `plan(multisession)` and `future.apply`?
